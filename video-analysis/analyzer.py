"""
üé¨ PICKLEBALL VIDEO ANALYSIS ENGINE
Ray's Pickleball Platform

This module provides AI-powered video analysis to extract player statistics
from match footage. It uses computer vision and pose estimation to detect
shots, track movement, and calculate performance metrics.

Requirements:
    pip install opencv-python mediapipe numpy

Optional (for better ball detection):
    pip install ultralytics  # YOLOv8

Usage:
    analyzer = PickleballAnalyzer()
    results = analyzer.analyze_video("match_footage.mp4")
    stats = results.to_avatar_stats()
"""

import cv2
import numpy as np
import json
from dataclasses import dataclass, asdict
from typing import List, Dict, Optional, Tuple
from enum import Enum
import time

# Try to import optional dependencies
try:
    import mediapipe as mp
    MEDIAPIPE_AVAILABLE = True
except ImportError:
    MEDIAPIPE_AVAILABLE = False
    print("Warning: MediaPipe not installed. Pose estimation disabled.")

try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    print("Warning: Ultralytics not installed. Advanced ball tracking disabled.")


class ShotType(Enum):
    """Types of shots in pickleball"""
    UNKNOWN = "unknown"
    SERVE = "serve"
    RETURN = "return"
    DINK = "dink"
    DRIVE = "drive"
    DROP = "drop"
    LOB = "lob"
    VOLLEY = "volley"
    OVERHEAD = "overhead"
    ATP = "atp"  # Around The Post
    ERNE = "erne"


@dataclass
class DetectedShot:
    """Represents a detected shot in the video"""
    frame_number: int
    timestamp: float
    shot_type: ShotType
    player_id: int  # 0 or 1 for doubles, 0-3 for singles
    ball_speed: Optional[float] = None  # pixels per frame
    placement_x: Optional[float] = None  # 0-1, left to right
    placement_y: Optional[float] = None  # 0-1, baseline to net
    confidence: float = 0.5


@dataclass
class PlayerMovement:
    """Tracks player movement across frames"""
    frame_number: int
    timestamp: float
    player_id: int
    position_x: float  # 0-1, court position
    position_y: float  # 0-1, court position
    velocity: float  # Movement speed


@dataclass
class AnalysisResults:
    """Complete analysis results from a video"""
    video_duration: float
    total_frames: int
    fps: float

    # Shot data
    shots: List[DetectedShot]
    shot_breakdown: Dict[str, int]

    # Movement data
    movements: List[PlayerMovement]
    court_coverage: float  # 0-100
    avg_recovery_time: float  # seconds

    # Performance metrics
    placement_accuracy: float  # 0-100
    avg_reaction_time_ms: int
    rally_lengths: List[int]
    unforced_errors: int
    winners: int

    # Confidence
    overall_confidence: float

    def to_avatar_stats(self) -> Dict[str, int]:
        """Convert analysis to 1-99 avatar stats"""

        # Calculate Power (based on shot speed and overhead frequency)
        overhead_ratio = self.shot_breakdown.get('overhead', 0) / max(len(self.shots), 1)
        drive_ratio = self.shot_breakdown.get('drive', 0) / max(len(self.shots), 1)
        power = min(99, max(1, int(
            50 + (overhead_ratio * 30) + (drive_ratio * 20)
        )))

        # Calculate Finesse (based on dinks, drops, and placement)
        dink_ratio = self.shot_breakdown.get('dink', 0) / max(len(self.shots), 1)
        drop_ratio = self.shot_breakdown.get('drop', 0) / max(len(self.shots), 1)
        finesse = min(99, max(1, int(
            40 + (dink_ratio * 30) + (drop_ratio * 20) + (self.placement_accuracy * 0.1)
        )))

        # Calculate Speed (based on court coverage and recovery)
        recovery_score = max(0, 100 - (self.avg_recovery_time * 50))  # Lower is better
        speed = min(99, max(1, int(
            30 + (self.court_coverage * 0.4) + (recovery_score * 0.3)
        )))

        # Calculate Court IQ (based on shot selection variety and winners)
        shot_variety = len([v for v in self.shot_breakdown.values() if v > 0])
        winner_ratio = self.winners / max(len(self.shots), 1)
        court_iq = min(99, max(1, int(
            40 + (shot_variety * 5) + (winner_ratio * 40) + (self.placement_accuracy * 0.15)
        )))

        # Calculate Consistency (based on unforced errors and rally length)
        error_ratio = self.unforced_errors / max(len(self.shots), 1)
        avg_rally = sum(self.rally_lengths) / max(len(self.rally_lengths), 1)
        consistency = min(99, max(1, int(
            70 - (error_ratio * 50) + (min(avg_rally, 20) * 1.5)
        )))

        return {
            'power': power,
            'finesse': finesse,
            'speed': speed,
            'court_iq': court_iq,
            'consistency': consistency,
            'confidence': {
                'power': self.overall_confidence * 0.9,
                'finesse': self.overall_confidence * 0.95,
                'speed': self.overall_confidence * 0.85,
                'court_iq': self.overall_confidence * 0.8,
                'consistency': self.overall_confidence * 0.9
            }
        }

    def to_dict(self) -> dict:
        """Convert to dictionary for JSON serialization"""
        return {
            'video_duration': self.video_duration,
            'total_frames': self.total_frames,
            'fps': self.fps,
            'shots': [{'frame': s.frame_number, 'type': s.shot_type.value, 'confidence': s.confidence} for s in self.shots],
            'shot_breakdown': self.shot_breakdown,
            'court_coverage': self.court_coverage,
            'avg_recovery_time': self.avg_recovery_time,
            'placement_accuracy': self.placement_accuracy,
            'avg_reaction_time_ms': self.avg_reaction_time_ms,
            'rally_lengths': self.rally_lengths,
            'unforced_errors': self.unforced_errors,
            'winners': self.winners,
            'overall_confidence': self.overall_confidence,
            'avatar_stats': self.to_avatar_stats()
        }


class CourtDetector:
    """Detects and tracks the pickleball court boundaries"""

    def __init__(self):
        self.court_corners = None
        self.perspective_matrix = None

    def detect_court(self, frame: np.ndarray) -> Optional[np.ndarray]:
        """
        Detect court lines and return corner points.
        Uses edge detection and Hough transform.
        """
        # Convert to grayscale
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Apply Gaussian blur
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)

        # Edge detection
        edges = cv2.Canny(blurred, 50, 150)

        # Find lines using Hough transform
        lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=100, maxLineGap=10)

        if lines is None:
            return None

        # Filter for court lines (white/light colored, horizontal/vertical)
        court_lines = self._filter_court_lines(lines, frame)

        # Find intersection points to get court corners
        corners = self._find_corners(court_lines)

        if corners is not None and len(corners) == 4:
            self.court_corners = corners
            self._calculate_perspective(corners)

        return self.court_corners

    def _filter_court_lines(self, lines: np.ndarray, frame: np.ndarray) -> List:
        """Filter lines to find likely court lines"""
        filtered = []
        for line in lines:
            x1, y1, x2, y2 = line[0]

            # Check if line is roughly horizontal or vertical
            angle = np.abs(np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi)
            if angle < 15 or angle > 75:  # Near horizontal or vertical
                filtered.append(line[0])

        return filtered

    def _find_corners(self, lines: List) -> Optional[np.ndarray]:
        """Find corner intersections from filtered lines"""
        # Simplified: return None if not enough lines
        if len(lines) < 4:
            return None

        # This would need more sophisticated logic for real implementation
        # For now, return a default court shape
        return None

    def _calculate_perspective(self, corners: np.ndarray):
        """Calculate perspective transform matrix"""
        # Standard court dimensions (ratio)
        width, height = 400, 200  # Arbitrary units

        dst_points = np.float32([
            [0, 0],
            [width, 0],
            [width, height],
            [0, height]
        ])

        self.perspective_matrix = cv2.getPerspectiveTransform(
            corners.astype(np.float32), dst_points
        )

    def world_to_court(self, x: float, y: float) -> Tuple[float, float]:
        """Convert world coordinates to normalized court coordinates (0-1)"""
        if self.perspective_matrix is None:
            return x, y

        point = np.array([[[x, y]]], dtype=np.float32)
        transformed = cv2.perspectiveTransform(point, self.perspective_matrix)

        # Normalize to 0-1
        court_x = transformed[0][0][0] / 400  # Assuming 400 width
        court_y = transformed[0][0][1] / 200  # Assuming 200 height

        return max(0, min(1, court_x)), max(0, min(1, court_y))


class BallTracker:
    """Tracks the pickleball across frames"""

    def __init__(self):
        self.last_position = None
        self.velocity = (0, 0)
        self.ball_history = []

        # Ball detection parameters
        self.ball_color_lower = np.array([20, 100, 100])  # Yellow-green lower bound
        self.ball_color_upper = np.array([40, 255, 255])  # Yellow-green upper bound

    def detect_ball(self, frame: np.ndarray) -> Optional[Tuple[float, float]]:
        """
        Detect ball position in frame using color detection.
        Returns (x, y) position or None if not found.
        """
        # Convert to HSV
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

        # Create mask for ball color
        mask = cv2.inRange(hsv, self.ball_color_lower, self.ball_color_upper)

        # Apply morphological operations
        kernel = np.ones((5, 5), np.uint8)
        mask = cv2.erode(mask, kernel, iterations=1)
        mask = cv2.dilate(mask, kernel, iterations=2)

        # Find contours
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if not contours:
            return None

        # Find the most circular contour of appropriate size
        best_match = None
        best_circularity = 0

        for contour in contours:
            area = cv2.contourArea(contour)

            # Filter by size (ball should be certain size range)
            if area < 50 or area > 5000:
                continue

            # Check circularity
            perimeter = cv2.arcLength(contour, True)
            if perimeter == 0:
                continue

            circularity = 4 * np.pi * area / (perimeter * perimeter)

            if circularity > best_circularity and circularity > 0.5:
                best_circularity = circularity
                M = cv2.moments(contour)
                if M["m00"] != 0:
                    cx = M["m10"] / M["m00"]
                    cy = M["m01"] / M["m00"]
                    best_match = (cx, cy)

        if best_match:
            # Calculate velocity
            if self.last_position:
                self.velocity = (
                    best_match[0] - self.last_position[0],
                    best_match[1] - self.last_position[1]
                )

            self.last_position = best_match
            self.ball_history.append(best_match)

            # Keep history limited
            if len(self.ball_history) > 30:
                self.ball_history.pop(0)

        return best_match

    def get_speed(self) -> float:
        """Get ball speed in pixels per frame"""
        return np.sqrt(self.velocity[0]**2 + self.velocity[1]**2)

    def detect_shot(self) -> Optional[ShotType]:
        """
        Analyze ball trajectory to detect shot type.
        Returns shot type if a shot was just made, None otherwise.
        """
        if len(self.ball_history) < 5:
            return None

        # Analyze trajectory
        recent = self.ball_history[-5:]

        # Calculate direction and speed changes
        directions = []
        speeds = []

        for i in range(1, len(recent)):
            dx = recent[i][0] - recent[i-1][0]
            dy = recent[i][1] - recent[i-1][1]
            directions.append(np.arctan2(dy, dx))
            speeds.append(np.sqrt(dx**2 + dy**2))

        # Detect shot based on trajectory characteristics
        avg_speed = np.mean(speeds)
        direction_change = np.std(directions)

        # High speed, straight trajectory = drive
        if avg_speed > 20 and direction_change < 0.3:
            return ShotType.DRIVE

        # Low speed, short trajectory = dink
        if avg_speed < 8 and len(self.ball_history) > 10:
            return ShotType.DINK

        # Upward trajectory = lob
        if len(directions) > 2 and all(d < -0.5 for d in directions[-3:]):
            return ShotType.LOB

        # Downward with medium speed = drop
        if avg_speed < 15 and len(directions) > 2 and all(d > 0.3 for d in directions[-3:]):
            return ShotType.DROP

        return ShotType.UNKNOWN


class PlayerTracker:
    """Tracks player positions and movements using pose estimation"""

    def __init__(self):
        self.pose = None
        if MEDIAPIPE_AVAILABLE:
            self.pose = mp.solutions.pose.Pose(
                static_image_mode=False,
                model_complexity=1,
                min_detection_confidence=0.5,
                min_tracking_confidence=0.5
            )

        self.player_positions = {}
        self.position_history = {0: [], 1: [], 2: [], 3: []}

    def detect_players(self, frame: np.ndarray) -> List[Tuple[int, float, float]]:
        """
        Detect player positions in frame.
        Returns list of (player_id, x, y) tuples.
        """
        if not MEDIAPIPE_AVAILABLE or self.pose is None:
            return []

        # Convert to RGB
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # Process frame
        results = self.pose.process(rgb)

        players = []

        if results.pose_landmarks:
            # Get hip position as player center
            landmarks = results.pose_landmarks.landmark

            # Use hip landmarks for position
            left_hip = landmarks[mp.solutions.pose.PoseLandmark.LEFT_HIP]
            right_hip = landmarks[mp.solutions.pose.PoseLandmark.RIGHT_HIP]

            center_x = (left_hip.x + right_hip.x) / 2
            center_y = (left_hip.y + right_hip.y) / 2

            # For now, assume single player (player 0)
            # Multi-player detection would need more sophisticated tracking
            players.append((0, center_x, center_y))

            self.position_history[0].append((center_x, center_y))
            if len(self.position_history[0]) > 60:
                self.position_history[0].pop(0)

        return players

    def get_court_coverage(self, player_id: int = 0) -> float:
        """Calculate court coverage percentage for a player"""
        history = self.position_history.get(player_id, [])

        if len(history) < 10:
            return 50.0  # Default

        # Calculate bounding box of positions
        xs = [p[0] for p in history]
        ys = [p[1] for p in history]

        x_range = max(xs) - min(xs)
        y_range = max(ys) - min(ys)

        # Coverage is area covered relative to court size
        coverage = (x_range * y_range) * 100 * 2  # Scale up

        return min(100, max(0, coverage))

    def get_recovery_time(self, player_id: int = 0) -> float:
        """Estimate average recovery time to ready position"""
        # This would need more sophisticated analysis
        # For now, return a reasonable default
        return 1.2  # seconds


class PickleballAnalyzer:
    """Main video analysis class"""

    def __init__(self):
        self.court_detector = CourtDetector()
        self.ball_tracker = BallTracker()
        self.player_tracker = PlayerTracker()

        # Analysis state
        self.shots = []
        self.movements = []
        self.rally_count = 0
        self.current_rally_length = 0
        self.rally_lengths = []
        self.unforced_errors = 0
        self.winners = 0

    def analyze_video(self, video_path: str, progress_callback=None) -> AnalysisResults:
        """
        Analyze a complete video file.

        Args:
            video_path: Path to the video file
            progress_callback: Optional callback(progress: float) for progress updates

        Returns:
            AnalysisResults object with all metrics
        """
        cap = cv2.VideoCapture(video_path)

        if not cap.isOpened():
            raise ValueError(f"Could not open video: {video_path}")

        # Get video properties
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps

        print(f"Analyzing video: {duration:.1f}s, {total_frames} frames @ {fps:.1f} fps")

        frame_number = 0
        last_shot_frame = 0

        # Process every Nth frame for efficiency
        frame_skip = max(1, int(fps / 10))  # ~10 samples per second

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # Skip frames for efficiency
            if frame_number % frame_skip != 0:
                frame_number += 1
                continue

            timestamp = frame_number / fps

            # Detect court (only first few frames)
            if frame_number < fps * 2:  # First 2 seconds
                self.court_detector.detect_court(frame)

            # Track ball
            ball_pos = self.ball_tracker.detect_ball(frame)

            # Detect shot
            if ball_pos:
                shot_type = self.ball_tracker.detect_shot()

                if shot_type and shot_type != ShotType.UNKNOWN:
                    # Avoid double-detection (minimum 0.3s between shots)
                    if frame_number - last_shot_frame > fps * 0.3:
                        shot = DetectedShot(
                            frame_number=frame_number,
                            timestamp=timestamp,
                            shot_type=shot_type,
                            player_id=0,
                            ball_speed=self.ball_tracker.get_speed(),
                            placement_x=ball_pos[0] / frame.shape[1],
                            placement_y=ball_pos[1] / frame.shape[0],
                            confidence=0.7
                        )
                        self.shots.append(shot)
                        last_shot_frame = frame_number
                        self.current_rally_length += 1

            # Track players
            players = self.player_tracker.detect_players(frame)

            for player_id, px, py in players:
                movement = PlayerMovement(
                    frame_number=frame_number,
                    timestamp=timestamp,
                    player_id=player_id,
                    position_x=px,
                    position_y=py,
                    velocity=0  # Would need calculation
                )
                self.movements.append(movement)

            # Progress callback
            if progress_callback and frame_number % (total_frames // 10) == 0:
                progress_callback(frame_number / total_frames)

            frame_number += 1

        cap.release()

        # Compile results
        return self._compile_results(duration, total_frames, fps)

    def _compile_results(self, duration: float, total_frames: int, fps: float) -> AnalysisResults:
        """Compile all analysis data into results object"""

        # Count shots by type
        shot_breakdown = {}
        for shot in self.shots:
            shot_type = shot.shot_type.value
            shot_breakdown[shot_type] = shot_breakdown.get(shot_type, 0) + 1

        # Calculate placement accuracy
        placements = [(s.placement_x, s.placement_y) for s in self.shots if s.placement_x is not None]
        placement_accuracy = 70.0  # Default
        if placements:
            # Higher accuracy if shots are well distributed (not all center)
            x_variance = np.var([p[0] for p in placements])
            y_variance = np.var([p[1] for p in placements])
            placement_accuracy = min(95, 50 + x_variance * 100 + y_variance * 100)

        # Estimate rally lengths (simplified)
        if not self.rally_lengths:
            # Estimate based on shot frequency
            if len(self.shots) > 5:
                avg_time_between_shots = duration / len(self.shots)
                estimated_rally = max(3, int(5 / avg_time_between_shots))
                self.rally_lengths = [estimated_rally] * (len(self.shots) // estimated_rally)

        # Calculate confidence based on detection quality
        confidence = 0.5
        if len(self.shots) > 10:
            confidence = min(0.95, 0.5 + len(self.shots) * 0.01)

        return AnalysisResults(
            video_duration=duration,
            total_frames=total_frames,
            fps=fps,
            shots=self.shots,
            shot_breakdown=shot_breakdown,
            movements=self.movements,
            court_coverage=self.player_tracker.get_court_coverage(),
            avg_recovery_time=self.player_tracker.get_recovery_time(),
            placement_accuracy=placement_accuracy,
            avg_reaction_time_ms=int(300 + np.random.normal(0, 50)),  # Placeholder
            rally_lengths=self.rally_lengths if self.rally_lengths else [5, 7, 4, 8, 6],
            unforced_errors=self.unforced_errors,
            winners=self.winners,
            overall_confidence=confidence
        )

    def analyze_frame(self, frame: np.ndarray) -> dict:
        """Analyze a single frame (for real-time analysis)"""
        ball_pos = self.ball_tracker.detect_ball(frame)
        players = self.player_tracker.detect_players(frame)

        return {
            'ball': ball_pos,
            'players': players,
            'shot_detected': self.ball_tracker.detect_shot()
        }


def analyze_video_file(video_path: str, output_path: str = None) -> dict:
    """
    Convenience function to analyze a video file and optionally save results.

    Args:
        video_path: Path to input video
        output_path: Optional path to save JSON results

    Returns:
        Dictionary of analysis results
    """
    analyzer = PickleballAnalyzer()

    def progress(p):
        print(f"Progress: {p*100:.1f}%")

    results = analyzer.analyze_video(video_path, progress_callback=progress)
    results_dict = results.to_dict()

    if output_path:
        with open(output_path, 'w') as f:
            json.dump(results_dict, f, indent=2)
        print(f"Results saved to: {output_path}")

    return results_dict


# CLI interface
if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("Usage: python analyzer.py <video_path> [output_json_path]")
        print("\nExample:")
        print("  python analyzer.py match.mp4 results.json")
        sys.exit(1)

    video_path = sys.argv[1]
    output_path = sys.argv[2] if len(sys.argv) > 2 else None

    print(f"\nüé¨ Pickleball Video Analyzer")
    print(f"{'='*50}")
    print(f"Input: {video_path}")

    try:
        results = analyze_video_file(video_path, output_path)

        print(f"\nüìä Analysis Complete!")
        print(f"{'='*50}")
        print(f"Duration: {results['video_duration']:.1f}s")
        print(f"Shots detected: {len(results['shots'])}")
        print(f"\nShot breakdown:")
        for shot_type, count in results['shot_breakdown'].items():
            print(f"  {shot_type}: {count}")

        print(f"\nüéÆ Avatar Stats:")
        stats = results['avatar_stats']
        print(f"  Power:       {stats['power']}")
        print(f"  Finesse:     {stats['finesse']}")
        print(f"  Speed:       {stats['speed']}")
        print(f"  Court IQ:    {stats['court_iq']}")
        print(f"  Consistency: {stats['consistency']}")

        print(f"\nConfidence: {results['overall_confidence']*100:.1f}%")

    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        sys.exit(1)
